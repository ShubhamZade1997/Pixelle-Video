# 🙋‍♀️ Pixelle-Video 常见问题解答 (FAQ)

### Pixelle-Video 是什么？它和传统视频制作有什么区别？

- **Pixelle-Video**：只需输入一个**主题关键词**，AI自动完成文案撰写→配图生成→语音合成→视频合成的全流程
- **传统视频制作**：需要手动编写脚本、拍摄/找素材、配音、剪辑、添加特效等多个复杂步骤
- **核心优势**：零门槛、零剪辑经验，让视频创作变成"一句话的事"

### 支持哪些安装方式？

Pixelle-Video 支持以下安装方法：

1. **标准安装（推荐）**：
   ```bash
   git clone https://github.com/AIDC-AI/Pixelle-Video.git
   cd Pixelle-Video
   uv run streamlit run web/app.py
   ```

2. **前置依赖**：
   - `uv` 包管理器（访问官方文档查看系统对应安装方法）
   - `ffmpeg` 视频处理工具：
     - **macOS**: `brew install ffmpeg`
     - **Ubuntu/Debian**: `sudo apt update && sudo apt install ffmpeg`
     - **Windows**: 从 ffmpeg.org 下载并配置环境变量 PATH

### 首次使用需要如何配置？

1. 打开 http://localhost:8501
2. 展开「⚙️ 系统配置」面板
3. 配置两个核心部分：
   - **LLM 配置**（用于生成文案）：
     - 选择预设模型（通义千问、GPT-4o、DeepSeek 等）
     - 或手动填写 API Key、Base URL 和 Model
   - **图像配置**（用于生成配图）：
     - **本地部署**：填写 ComfyUI 地址（默认 http://127.0.0.1:8188）
     - **云端部署**：填写 RunningHub API Key
4. 点击「保存配置」完成设置

### 支持哪些视频生成模式？

Pixelle-Video 提供两种主要生成模式：

1. **AI 生成内容**：
   - 只需输入主题关键词
   - AI 自动创作完整文案并生成视频
   - 适合场景：快速创作，让 AI 代写脚本
   - 示例："为什么要养成阅读习惯"

2. **固定文案内容**：
   - 直接输入完整文案内容
   - 跳过 AI 文案创作环节，直接进入视频生成
   - 适合场景：已有现成文案，只需生成配图和合成视频

### 如何自定义音频效果？

音频定制包含以下选项：

- **背景音乐 (BGM)**：
  - 无 BGM：纯人声解说
  - 内置音乐：选择预置背景音乐（如 default.mp3）
  - 自定义音乐：将 MP3/WAV 文件放入 `bgm/` 文件夹
  - 点击「试听 BGM」预览效果

- **语音合成 (TTS)**：
  - 支持多种 TTS 工作流（Edge-TTS、Index-TTS 等）
  - 系统自动扫描 `workflows/` 文件夹中的可用选项
  - 输入测试文本，点击「预览语音」测试效果

- **声音克隆**：
  - 上传参考音频（MP3/WAV/FLAC 格式）
  - 适用于支持声音克隆的 TTS 工作流
  - 上传后可直接在预览中使用

### 如何自定义视觉效果？

视觉定制包含以下方面：

- **图像生成工作流**：
  - 选择预置工作流（如 `image_flux.json`）
  - 支持本地部署和云端部署
  - 高级用户可添加自定义 ComfyUI 工作流到 `workflows/` 文件夹

- **图像尺寸**：
  - 设置宽度和高度（默认 1024×1024 像素）
  - 注意：不同模型对尺寸有不同要求

- **风格控制**：
  - 通过提示词前缀（Prompt Prefix）控制整体风格
  - 要求使用英文描述
  - 示例："Minimalist black-and-white matchstick figure style illustration, clean lines, simple sketch style"
  - 点击「预览风格」测试效果

- **视频模板**：
  - 按尺寸分组（竖屏/横屏/方形）
  - 点击「预览模板」测试不同效果
  - 高级用户可在 `templates/` 文件夹创建自定义 HTML 模板

### 支持哪些 AI 模型？

Pixelle-Video 支持多种 AI 模型提供商：

- **LLM 模型**：GPT、通义千问、DeepSeek、Ollama（本地）等
- **图像生成**：ComfyUI 支持的各类模型（FLUX、SDXL 等）
- **TTS 引擎**：Edge-TTS、Index-TTS、ChatTTS 等

采用模块化架构，可灵活替换任意组件 - 例如可将图像生成模型替换为 FLUX，或将 TTS 替换为 ChatTTS。

### 运行成本是多少？

Pixelle-Video 提供三种成本方案：

1. **完全免费方案**：
   - LLM：Ollama（本地运行）
   - 图像生成：本地 ComfyUI 部署
   - 总成本：0 元

2. **推荐平衡方案**：
   - LLM：通义千问（成本极低，性价比高）
   - 图像生成：本地 ComfyUI 部署
   - 成本：仅文本生成的少量 API 费用

3. **纯云端方案**：
   - LLM：OpenAI API
   - 图像生成：RunningHub 云服务
   - 成本：较高，但无需本地硬件

**选择建议**：有 GPU 显卡建议使用完全免费方案；否则推荐通义千问+本地 ComfyUI 组合，性价比最高。

### 视频生成需要多长时间？

生成时间取决于以下因素：
- 脚本中的分镜数量
- 网络连接速度
- AI 推理速度（本地 vs 云端）
- 视频长度和分辨率

**典型生成时间**：大多数视频需要 **2-10 分钟** 完成。界面会实时显示进度：生成文案 → 生成配图 → 合成语音 → 合成视频。

### 视频效果不满意怎么办？

可以尝试以下优化方案：

- **文案质量**：
  - 更换 LLM 模型（不同模型写作风格各异）
  - 使用"固定文案内容"模式，输入自己优化的脚本

- **图像质量**：
  - 调整图像尺寸以匹配模型要求
  - 修改提示词前缀改变视觉风格
  - 尝试不同的 ComfyUI 工作流

- **音频质量**：
  - 切换 TTS 工作流（Edge-TTS vs Index-TTS 等）
  - 上传参考音频进行声音克隆
  - 调整 TTS 参数

- **视频布局**：
  - 尝试不同的视频模板
  - 更改视频尺寸（竖屏/横屏/方形）

### 生成的视频保存在哪里？

所有生成的视频自动保存到项目目录的 `output/` 文件夹中。生成完成后，界面会显示详细信息：
- 视频时长
- 文件大小
- 分镜数量
- 下载链接

### 如何排查常见错误？

1. **FFmpeg 错误**：
   - 通过 `ffmpeg -version` 验证安装
   - 确保 ffmpeg 在系统 PATH 中

2. **API 连接问题**：
   - 验证 API Key 是否正确
   - 在系统配置中测试 LLM 连接
   - 对于 ComfyUI：点击图像配置中的"测试连接"

3. **图像生成失败**：
   - 确保 ComfyUI 服务正在运行
   - 检查图像尺寸是否被模型支持
   - 验证工作流文件是否存在于 `workflows/` 文件夹

4. **音频生成问题**：
   - 确认所选 TTS 工作流配置正确
   - 对于声音克隆：验证参考音频格式是否支持

### 如何扩展 Pixelle-Video 的功能？

Pixelle-Video 基于 ComfyUI 架构，支持深度定制：

- **自定义工作流**：添加自定义 ComfyUI 工作流到 `workflows/` 文件夹
- **自定义模板**：在 `templates/` 文件夹创建 HTML 模板
- **自定义 BGM**：将音乐文件放入 `bgm/` 文件夹
- **高级集成**：利用 ComfyUI 生态，集成任何自定义节点

原子能力设计意味着可以自由组合任意组件 - 替换文本生成、图像模型、TTS 引擎或视频模板，满足个性化需求。

### 有哪些社区资源？

- **GitHub 仓库**：https://github.com/AIDC-AI/Pixelle-Video
- **问题反馈**：通过 GitHub Issues 提交 bug 或功能请求
- **社区支持**：加入讨论群组获取帮助和分享经验
- **模板库**：查看所有可用模板及其效果
- **贡献代码**：项目在 MIT 许可证下欢迎贡献

💡 **提示**：如果在此 FAQ 中找不到您需要的答案，请在 GitHub 提交 issue 或加入社区讨论。我们会根据用户反馈持续更新此 FAQ！
